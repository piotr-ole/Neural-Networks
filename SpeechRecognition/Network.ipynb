{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pobieranie danych z bucketa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate --no-proxy \"url\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wypakowanie danych do folderu /content/ na Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "tar = tarfile.open('/content/audioSpectrograms2.tar.gz')\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcje służące do wizualizacji wyników:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "def visualise_learining_process(epochs, losses_on_test, losses_on_train, xtick):\n",
    "    plt.plot(epochs, losses_on_test, 'yo')\n",
    "    plt.plot(epochs, losses_on_train, 'bo')\n",
    "    plt.title(\"Value of the cost function\")\n",
    "    plt.legend(['test', 'train'])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.xticks(np.arange(0, len(epochs), xtick))\n",
    "    plt.show()\n",
    "\n",
    "def visualise_errors_for_class(classify_table, class_index):\n",
    "    '''\n",
    "    Plots number of incorrect classifications of elements from specified class with division where elements were\n",
    "    classified by network.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    class_index: class number\n",
    "    '''\n",
    "    indices = np.arange(10)\n",
    "    p = list()\n",
    "    table = copy.deepcopy(classify_table)\n",
    "    table[np.argmax(table, 0), np.argmax(table, 1)] = 0\n",
    "    plt.bar(indices, table[:, class_index])\n",
    "    plt.xticks(indices)\n",
    "    plt.title(\"Number of incorrect classifications of elements from class {}\".format(class_index))\n",
    "    plt.xlabel(\"Class returned by network\")\n",
    "    plt.show()\n",
    "    \n",
    "def visualise_errors_by_class(classify_table):\n",
    "    '''\n",
    "    Plots a barplot with classes on x-axis and number of bad classifications in each class. Colors division represents\n",
    "    proportion showing to which class were classified examples that were classified incorrect.\n",
    "    '''\n",
    "    indices = np.arange(10)\n",
    "    p = list()\n",
    "    table = copy.deepcopy(classify_table)\n",
    "    table[np.argmax(table, 0), np.argmax(table, 1)] = 0\n",
    "    p.append(plt.bar(indices, table[:, 0]))\n",
    "    for i in range(1, 10):\n",
    "        p.append(plt.bar(indices, table[:, i], bottom = np.sum(table[:, 0:i], 1)))\n",
    "    plt.title(\"Number of incorrect classifications\")\n",
    "    plt.xticks(indices)\n",
    "    plt.xlabel(\"Correct class\")\n",
    "    plt.legend(list(range(0,10)), title = \"class returned by network\", bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    \n",
    "def visualise_effectiveness_by_class(classify_table):\n",
    "    '''\n",
    "    Plots a barplot showing rate of correct classified examples for each class separately.\n",
    "    '''\n",
    "    indices = np.arange(10)\n",
    "    results = [ classify_table[i,i] / np.sum(classify_table[i, :]) for i in range(10)]\n",
    "    plt.bar(indices, results, color = ['#2ca25f', '#2c7fb8'])\n",
    "    plt.title(\"Rate of correct classifications to each class\")\n",
    "    plt.xlabel('Class')\n",
    "    plt.xticks(indices)\n",
    "    plt.show()\n",
    "    \n",
    "def roc_analysis(labels, results, xlim, ylim, draw_diag = False):\n",
    "    '''\n",
    "    Plots ROC curve with AUC values calculated for elements from testing set with class division.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    xlim, ylim: lists of two parameters specifing start and end of respectively x and y axis\n",
    "    '''\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(0, 10):\n",
    "        fpr[i], tpr[i], _ = roc_curve(labels[i, :], results[i, :])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    plt.figure(figsize=(7, 5), dpi= 80)\n",
    "    for i in range(0, 10):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, label='ROC curve (AUC = {:0.5f}) for {} class'.format(roc_auc[i], i))\n",
    "    if (draw_diag == True):\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlabel('False Positive Rate', size = 12)\n",
    "    plt.ylabel('True Positive Rate', size = 12)\n",
    "    plt.title('ROC curve for binary classification task', size = 13)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dedykowany Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/utkuozbulak/pytorch-custom-dataset-examples/blob/master/src/custom_datasets.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset  # For custom datasets\n",
    "\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            img_path (string): path to the folder where images are\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        # Transforms\n",
    "        self.trans = transform\n",
    "        # Read the csv file\n",
    "        self.data_info = pd.read_csv(csv_path, header=0, sep = ';')\n",
    "        # First column contains the image paths\n",
    "        self.data_info.iloc[:, 0] = self.data_info.iloc[:, 0].apply(lambda line: '/content' + line[1:]) # for colab purpose\n",
    "        self.image_arr = np.asarray(self.data_info.iloc[:, 0])\n",
    "        # Third column is the labels\n",
    "        self.label_arr = np.asarray(self.data_info.iloc[:, 2])\n",
    "        self.data_len = len(self.data_info.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image name from the pandas df\n",
    "        single_image_name = self.image_arr[index]\n",
    "        # Open image\n",
    "        img_as_img = Image.open(single_image_name)\n",
    "\n",
    "        img_as_tensor = self.trans(img_as_img)\n",
    "\n",
    "        # Get label(class) of the image based on the cropped pandas column\n",
    "        single_image_label = self.label_arr[index]\n",
    "        \n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model sieci konwolucyjnej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Napisac wstepnie jakis convnet, a potem sie sproboje LSTM jak to zadziala\n",
    "class NetModel(nn.Module):\n",
    "    def __init__(self, number_of_classes = 10):\n",
    "        super(NetModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 8, stride = 1, kernel_size = 5, padding = 1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, stride = 1, kernel_size = 5, padding = 0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.linear1 = nn.Linear(16 * 16 * 16, 300) # Tutaj trzeba zmienic wartosci (przeliczyc) \n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(p = 0.5)\n",
    "        self.linear2 = nn.Linear(300, number_of_classes)\n",
    "        \n",
    "        self.net = nn.Sequential(self.conv1, self.relu1, self.maxpool1, \n",
    "                                 self.conv2, self.relu2, self.maxpool2)\n",
    "                                             \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(-1, x.shape[0] , 16 * 16 * 16) # Tutaj zmienic wartosci\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model sieci LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, number_of_classes = 10):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 8, stride = 1, kernel_size = 5, padding = 1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.LSTM = nn.LSTM(input_size= 36 * 36 * 8, hidden_size= 300)\n",
    "        self.relu_lstm = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(300, 84) # Tutaj trzeba zmienic wartosci (przeliczyc) \n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(p = 0.5)\n",
    "        self.linear2 = nn.Linear(84, number_of_classes)\n",
    "        \n",
    "        self.net = nn.Sequential(self.conv1, self.relu1, self.maxpool1)\n",
    "                                             \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(-1, x.shape[0] , 36 * 36 * 8) # Tutaj zmienic wartosci\n",
    "        x = self.LSTM(x)\n",
    "        x = self.relu_lstm(x[0])\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasa sieci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adadelta, Adam\n",
    "\n",
    "# Others\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "\n",
    "# Network\n",
    "class Network:\n",
    "    \n",
    "    def __init__(self, batch_size, learning_rate, l2_reg):\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = learning_rate\n",
    "        self.l2_reg = l2_reg\n",
    "        self.train_set , self.test_set = self.datasets()\n",
    "        self.train_loader, self.test_loader = self.data_loaders(self.batch_size)\n",
    "        self.model = NetModel(number_of_classes = 10).cuda() # dopisac model\n",
    "        self.optimizer = Adam(self.model.parameters(), lr = self.lr, weight_decay=self.l2_reg)\n",
    "        self.loss_fun = nn.CrossEntropyLoss()\n",
    "        self.classify_table = np.zeros((10,10))\n",
    "        self.training_tracking = [list(), list()]\n",
    "\n",
    "        \n",
    "    def data_loaders(self, batch_train_size): ### Tutaj na batch size test trzeba ustawic rozmiar zbioru\n",
    "        train_loader = DataLoader(self.train_set, batch_size = batch_train_size, shuffle = True, num_workers = 4)\n",
    "        test_loader = DataLoader(self.test_set, batch_size = len(self.test_set), shuffle = False, num_workers = 4)\n",
    "        return train_loader, test_loader\n",
    "    \n",
    "    def datasets(self):\n",
    "        train_set = AudioDataset('/content/train.csv', transform = transforms.ToTensor())\n",
    "        test_set = AudioDataset('/content/test.csv', transform = transforms.ToTensor())\n",
    "        return train_set, test_set\n",
    "\n",
    "    def train(self, epochs):\n",
    "        #entering training mode\n",
    "        cuda0 = torch.device('cuda:0')\n",
    "        for epoch in range(1 , epochs + 1):\n",
    "            for i, (img, label) in enumerate(self.train_loader):\n",
    "                img = img.to(cuda0)\n",
    "                label = label.to(cuda0)\n",
    "                #set_trace()\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "                prediction = self.model(img)\n",
    "                #set_trace()\n",
    "                loss = self.loss_fun(prediction[0], label) # tu moze sie sypac ten indexer jak mam nie rgb obrazki\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                test_eval = self.test_evaluate()\n",
    "                #print(i)\n",
    "            test_eval = self.test_evaluate()\n",
    "            train_eval = self.train_evaluate()\n",
    "            self.training_tracking[0].append(float(test_eval[1]))\n",
    "            self.training_tracking[1].append(float(train_eval[1]))\n",
    "            print('Epoch {}: acc on train: {}, acc on test {}'.format(epoch, train_eval[0], test_eval[0]))\n",
    "        self.visualise_learing_process() # to jest do zmiany\n",
    "                \n",
    "    \n",
    "    def train_evaluate(self):\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            class_table = np.zeros((10,10))\n",
    "            loss = 0.0\n",
    "            true_counter = 0\n",
    "            cuda0 = torch.device('cuda:0')\n",
    "            for i, (img, label) in enumerate(self.train_loader):\n",
    "                img = img.to(cuda0)\n",
    "                label = label.to(cuda0)\n",
    "                prediction = self.model(img)\n",
    "                loss += self.loss_fun(prediction[0], label) # to prediction moze miec inny wymiar\n",
    "                _ , prediction = torch.max(prediction[0].data, 1)\n",
    "                self.update_classify_table(class_table, prediction, label.data)\n",
    "                true_counter += torch.sum(prediction == label.data)\n",
    "            return (true_counter.cpu().numpy() / len(self.train_set)) , (loss * self.batch_size / len(self.train_set))\n",
    "\n",
    "    def test_evaluate(self):\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            self.classify_table = np.zeros((10,10))\n",
    "            true_counter = 0\n",
    "            loss = 0.0\n",
    "            cuda0 = torch.device('cuda:0')\n",
    "            for i, (img, label) in enumerate(self.test_loader):\n",
    "                img = img.to(cuda0)\n",
    "                label = label.to(cuda0)\n",
    "                prediction = self.model(img)\n",
    "                loss += self.loss_fun(prediction[0], label)\n",
    "                _ , prediction = torch.max(prediction[0].data, 1)  # tu moze sie sypac ten indexer jak mam nie rgb obrazki\n",
    "                self.update_classify_table(self.classify_table, prediction, label.data)\n",
    "                true_counter += torch.sum(prediction == label.data)\n",
    "            return (true_counter.cpu().numpy() / len(self.test_set)) , loss \n",
    "    \n",
    "    \n",
    "    def update_classify_table(self, classify_table, predictions, labels):\n",
    "        for lab, pred in zip(labels, predictions):\n",
    "            classify_table[lab, pred] += 1\n",
    "    \n",
    "    def vector_label(self, labels):\n",
    "        lab = np.zeros((10, len(labels)))\n",
    "        lab[labels, range(len(labels))] = 1\n",
    "        return lab\n",
    "            \n",
    "    #visualisation\n",
    "    def visualise_learing_process(self): # tutaj poprawic\n",
    "        epochs = range(1, len(self.training_tracking[0]) + 1)\n",
    "        visualise_learining_process(epochs, self.training_tracking[0], self.training_tracking[1], 3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(batch_size = 100, learning_rate = 0.001, l2_reg = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "net.train(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
